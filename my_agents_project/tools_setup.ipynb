{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1740848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Sending initial request to the model ---\n",
      "\n",
      "--- 2. Received response from the model ---\n",
      "{\n",
      "  \"id\": \"id_liEx0lB7XwtiISuPX\",\n",
      "  \"model\": \"asi1-mini\",\n",
      "  \"executable_data\": [],\n",
      "  \"intermediate_steps\": [],\n",
      "  \"conversation_id\": null,\n",
      "  \"thought\": [\n",
      "    \"\\n\\n\"\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\",\n",
      "        \"reasoning\": \"\\n\\n\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_xRTac\",\n",
      "            \"index\": 0,\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"get_weather\",\n",
      "              \"arguments\": \"{\\\"longitude\\\":-0.1278,\\\"latitude\\\":51.5074}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 140,\n",
      "    \"completion_tokens\": 8,\n",
      "    \"total_tokens\": 148\n",
      "  }\n",
      "}\n",
      "\n",
      "--- 3. Model decided to use a tool. ---\n",
      "\n",
      "---> Executing get_weather(latitude=51.5074, longitude=-0.1278)\n",
      "<--- Tool execution returned: {\"temperature\": 15, \"unit\": \"celsius\", \"description\": \"Partly cloudy with a slight breeze.\"}\n",
      "\n",
      "--- 4. Sending tool output back to the model for a final answer ---\n",
      "\n",
      "--- 5. Received final, user-facing response ---\n",
      "Assistant: The current weather in London is **15Â°C** with partly cloudy skies and a slight breeze. It looks like a pleasant day out there! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# It's best practice to load API keys from environment variables.\n",
    "# For demonstration, a placeholder is included. Replace it or set the variable.\n",
    "API_KEY = os.getenv('ASI_ONE_API_KEY')\n",
    "BASE_URL = \"https://api.asi1.ai/v1\"\n",
    "\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- Tool Definition ---\n",
    "# This is the actual Python function that gets executed.\n",
    "# In a real-world scenario, this would make a request to a weather API.\n",
    "def get_weather(latitude, longitude):\n",
    "    \"\"\"\n",
    "    Simulates fetching weather data for a given latitude and longitude.\n",
    "    \"\"\"\n",
    "    print(f\"\\n---> Executing get_weather(latitude={latitude}, longitude={longitude})\")\n",
    "    weather_data = {\n",
    "        \"temperature\": 15,\n",
    "        \"unit\": \"celsius\",\n",
    "        \"description\": \"Partly cloudy with a slight breeze.\"\n",
    "    }\n",
    "    # The tool's output must be a string.\n",
    "    return json.dumps(weather_data)\n",
    "\n",
    "# --- Tool Schema for the Model ---\n",
    "# This is the JSON schema that describes the tool to the language model.\n",
    "# It tells the model the tool's name, purpose, and required parameters.\n",
    "get_weather_tool_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current temperature for a specific location using its latitude and longitude.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"latitude\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The latitude of the location, e.g., 51.5074\"\n",
    "                },\n",
    "                \"longitude\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The longitude of the location, e.g., -0.1278\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"latitude\", \"longitude\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def run_conversation():\n",
    "    \"\"\"\n",
    "    Manages the conversation flow, including making API calls and executing tools.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful weather assistant. When a user asks for the weather, use the get_weather tool to find the information. Do not make up weather data.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What's the current weather in London (latitude 51.5074 and longitude -0.1278)?\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    print(\"--- 1. Sending initial request to the model ---\")\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"asi1-mini\",\n",
    "        \"messages\": messages,\n",
    "        \"tools\": [get_weather_tool_schema],\n",
    "        \"tool_choice\": \"auto\" # 'auto' lets the model decide whether to use a tool.\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(f\"{BASE_URL}/chat/completions\", headers=headers, json=payload)\n",
    "        response.raise_for_status() \n",
    "        response_json = response.json()\n",
    "        \n",
    "        print(\"\\n--- 2. Received response from the model ---\")\n",
    "        print(json.dumps(response_json, indent=2))\n",
    "\n",
    "        response_message = response_json[\"choices\"][0][\"message\"]\n",
    "\n",
    "        \n",
    "        if not response_message.get(\"tool_calls\"):\n",
    "            print(\"\\n--- Model responded directly without using a tool. ---\")\n",
    "            print(f\"Assistant: {response_message['content']}\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n--- 3. Model decided to use a tool. ---\")\n",
    "        \n",
    "        messages.append(response_message)\n",
    "        \n",
    "       \n",
    "        tool_calls = response_message[\"tool_calls\"]\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call[\"function\"][\"name\"]\n",
    "            \n",
    "            if function_name == \"get_weather\":\n",
    "                \n",
    "                function_args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "                \n",
    "               \n",
    "                function_response = get_weather(\n",
    "                    latitude=function_args.get(\"latitude\"),\n",
    "                    longitude=function_args.get(\"longitude\")\n",
    "                )\n",
    "                \n",
    "                print(f\"<--- Tool execution returned: {function_response}\")\n",
    "\n",
    "               \n",
    "                messages.append({\n",
    "                    \"tool_call_id\": tool_call[\"id\"],\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response\n",
    "                })\n",
    "\n",
    " \n",
    "        print(\"\\n--- 4. Sending tool output back to the model for a final answer ---\")\n",
    "        second_payload = {\n",
    "            \"model\": \"asi1-mini\",\n",
    "            \"messages\": messages\n",
    "        }\n",
    "        second_response = requests.post(f\"{BASE_URL}/chat/completions\", headers=headers, json=second_payload)\n",
    "        second_response.raise_for_status()\n",
    "        \n",
    "        final_response_json = second_response.json()\n",
    "        final_answer = final_response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        print(\"\\n--- 5. Received final, user-facing response ---\")\n",
    "        print(f\"Assistant: {final_answer}\")\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP Error: {e}\")\n",
    "        print(f\"Response Body: {e.response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Run the main conversation function\n",
    "if __name__ == \"__main__\":\n",
    "    run_conversation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
